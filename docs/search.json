[
  {
    "objectID": "week9/index.html",
    "href": "week9/index.html",
    "title": "Week 9: K-nearest neighbours and hierarchical clustering",
    "section": "",
    "text": "HOML Ch 20, 21"
  },
  {
    "objectID": "week9/index.html#main-reference",
    "href": "week9/index.html#main-reference",
    "title": "Week 9: K-nearest neighbours and hierarchical clustering",
    "section": "",
    "text": "HOML Ch 20, 21"
  },
  {
    "objectID": "week9/index.html#what-you-will-learn-this-week",
    "href": "week9/index.html#what-you-will-learn-this-week",
    "title": "Week 9: K-nearest neighbours and hierarchical clustering",
    "section": "What you will learn this week",
    "text": "What you will learn this week\n\nDefining distance measure\nk-means algorithm\nHierarchical algorithms\nMaking and using dendrograms"
  },
  {
    "objectID": "week9/index.html#assignments",
    "href": "week9/index.html#assignments",
    "title": "Week 9: K-nearest neighbours and hierarchical clustering",
    "section": "Assignments",
    "text": "Assignments\n\nProject is due on Friday 17 May."
  },
  {
    "objectID": "week7/index.html",
    "href": "week7/index.html",
    "title": "Week 7: Explainable artificial intelligence (XAI)",
    "section": "",
    "text": "Molnar 8.1, 8.5, 9.2-9.6"
  },
  {
    "objectID": "week7/index.html#main-reference",
    "href": "week7/index.html#main-reference",
    "title": "Week 7: Explainable artificial intelligence (XAI)",
    "section": "",
    "text": "Molnar 8.1, 8.5, 9.2-9.6"
  },
  {
    "objectID": "week7/index.html#what-you-will-learn-this-week",
    "href": "week7/index.html#what-you-will-learn-this-week",
    "title": "Week 7: Explainable artificial intelligence (XAI)",
    "section": "What you will learn this week",
    "text": "What you will learn this week\n\nLocal explainability\nLIME\nShapley values"
  },
  {
    "objectID": "week7/index.html#assignments",
    "href": "week7/index.html#assignments",
    "title": "Week 7: Explainable artificial intelligence (XAI)",
    "section": "Assignments",
    "text": "Assignments\n\nAssignment 3 is due on Friday 26 April."
  },
  {
    "objectID": "week5/index.html",
    "href": "week5/index.html",
    "title": "Week 5: Trees and forests",
    "section": "",
    "text": "ISLR 8.1, 8.2"
  },
  {
    "objectID": "week5/index.html#main-reference",
    "href": "week5/index.html#main-reference",
    "title": "Week 5: Trees and forests",
    "section": "",
    "text": "ISLR 8.1, 8.2"
  },
  {
    "objectID": "week5/index.html#what-you-will-learn-this-week",
    "href": "week5/index.html#what-you-will-learn-this-week",
    "title": "Week 5: Trees and forests",
    "section": "What you will learn this week",
    "text": "What you will learn this week\n\nClassification trees, algorithm, stopping rules\nDifference between algorithm and parametric methods, especially trees vs LDA\nForests: ensembles of bagged trees\nDiagnostics: vote matrix, variable importance, proximity\nBoosted trees"
  },
  {
    "objectID": "week5/index.html#assignments",
    "href": "week5/index.html#assignments",
    "title": "Week 5: Trees and forests",
    "section": "Assignments",
    "text": "Assignments\n\nAssignment 2 is due on Friday 12 April."
  },
  {
    "objectID": "week3/index.html",
    "href": "week3/index.html",
    "title": "Week 3: Re-sampling and regularisation",
    "section": "",
    "text": "ISLR 5.1, 5.2, 6.2, 6.4"
  },
  {
    "objectID": "week3/index.html#main-reference",
    "href": "week3/index.html#main-reference",
    "title": "Week 3: Re-sampling and regularisation",
    "section": "",
    "text": "ISLR 5.1, 5.2, 6.2, 6.4"
  },
  {
    "objectID": "week3/index.html#what-you-will-learn-this-week",
    "href": "week3/index.html#what-you-will-learn-this-week",
    "title": "Week 3: Re-sampling and regularisation",
    "section": "What you will learn this week",
    "text": "What you will learn this week\n\nCross-validation for parameter tuning\nBootstrapping for understanding variance of parameter estimates\nWhat can go wrong in high-d\nRegularisation using ridge and lasso when there is insufficient observations relative to number of variables"
  },
  {
    "objectID": "week3/index.html#assignments",
    "href": "week3/index.html#assignments",
    "title": "Week 3: Re-sampling and regularisation",
    "section": "Assignments",
    "text": "Assignments\n\nAssignment 1 is due on Friday 22 March."
  },
  {
    "objectID": "week12/index.html#presentations-from-masters-students",
    "href": "week12/index.html#presentations-from-masters-students",
    "title": "Week 12: Project presentations by Masters students",
    "section": "Presentations from Masters students",
    "text": "Presentations from Masters students"
  },
  {
    "objectID": "week10/index.html",
    "href": "week10/index.html",
    "title": "Week 10: Model-based clustering and self-organising maps",
    "section": "",
    "text": "HOML Ch 22"
  },
  {
    "objectID": "week10/index.html#main-reference",
    "href": "week10/index.html#main-reference",
    "title": "Week 10: Model-based clustering and self-organising maps",
    "section": "",
    "text": "HOML Ch 22"
  },
  {
    "objectID": "week10/index.html#what-you-will-learn-this-week",
    "href": "week10/index.html#what-you-will-learn-this-week",
    "title": "Week 10: Model-based clustering and self-organising maps",
    "section": "What you will learn this week",
    "text": "What you will learn this week\n\nModels of multimodality using Gaussian mixtures\nFitting model-based clustering\nDiagnostics for the model fit\nSelf-organising maps and dimension reduction"
  },
  {
    "objectID": "week10/index.html#assignments",
    "href": "week10/index.html#assignments",
    "title": "Week 10: Model-based clustering and self-organising maps",
    "section": "Assignments",
    "text": "Assignments\n\nProject is due on Friday 17 May."
  },
  {
    "objectID": "week1/index.html",
    "href": "week1/index.html",
    "title": "Week 1: Foundations of machine learning",
    "section": "",
    "text": "ISLR 2.1, 2.2"
  },
  {
    "objectID": "week1/index.html#main-reference",
    "href": "week1/index.html#main-reference",
    "title": "Week 1: Foundations of machine learning",
    "section": "",
    "text": "ISLR 2.1, 2.2"
  },
  {
    "objectID": "week1/index.html#what-you-will-learn-this-week",
    "href": "week1/index.html#what-you-will-learn-this-week",
    "title": "Week 1: Foundations of machine learning",
    "section": "What you will learn this week",
    "text": "What you will learn this week\n\nFraming the problems\nNotation and math\nBias variance-tradeoff\nFitting your models: training/test splits, optimisation\nMeasuring fit: accuracy, loss\nDiagnostics: residuals\nFeature engineering: combining variables to better match purpose and help the model fitting"
  },
  {
    "objectID": "week1/index.html#lecture-slides",
    "href": "week1/index.html#lecture-slides",
    "title": "Week 1: Foundations of machine learning",
    "section": "Lecture slides",
    "text": "Lecture slides\n\nhtml\npdf\nquarto"
  },
  {
    "objectID": "week1/index.html#tutorial-instructions",
    "href": "week1/index.html#tutorial-instructions",
    "title": "Week 1: Foundations of machine learning",
    "section": "Tutorial instructions",
    "text": "Tutorial instructions\nInstructions:\n\nhtml\nquarto"
  },
  {
    "objectID": "week1/index.html#assignments",
    "href": "week1/index.html#assignments",
    "title": "Week 1: Foundations of machine learning",
    "section": "Assignments",
    "text": "Assignments"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ETC3250/5250 Introduction to Machine Learning",
    "section": "",
    "text": "Professor Di Cook\n\nEmail: etc3250.clayton-x@monash.edu\nConsultation:"
  },
  {
    "objectID": "index.html#lecturerchief-examiner",
    "href": "index.html#lecturerchief-examiner",
    "title": "ETC3250/5250 Introduction to Machine Learning",
    "section": "",
    "text": "Professor Di Cook\n\nEmail: etc3250.clayton-x@monash.edu\nConsultation:"
  },
  {
    "objectID": "index.html#tutors",
    "href": "index.html#tutors",
    "title": "ETC3250/5250 Introduction to Machine Learning",
    "section": "Tutors",
    "text": "Tutors\n\nPatrick Li\n\nTutorials:\nConsultation:\n\nHarriet Mason\n\nTutorials:\nConsultation:\n\nJayani Lakshika\n\nTutorials:\nConsultation:\n\nKrisanat Anukarnsakulchularp\n\nTutorials:\nConsultation:"
  },
  {
    "objectID": "index.html#weekly-schedule",
    "href": "index.html#weekly-schedule",
    "title": "ETC3250/5250 Introduction to Machine Learning",
    "section": "Weekly schedule",
    "text": "Weekly schedule\n\nLecture: Wed 1:05-2:45pm\nTutorial: 1.5 hours\nWeekly learning quizzes due Mondays 9am\n\n\n\n\nWeek\nTopic\nReference\nAssessments\n\n\n\n\n26 Feb\nFoundations of machine learning\nISLR 2.1, 2.2\n\n\n\n04 Mar\nVisualising your data and models\nCook and Laa Ch 1, 3, 4, 5, 6, 13\n\n\n\n11 Mar\nRe-sampling and regularisation\nISLR 5.1, 5.2, 6.2, 6.4\n\n\n\n18 Mar\nLogistic regression and discriminant analysis\nISLR 4.3, 4.4\nAssignment 1\n\n\n25 Mar\nTrees and forests\nISLR 8.1, 8.2\n\n\n\n01 Apr\nMid-semester break\n\n\n\n\n08 Apr\nNeural networks and deep learning\nISLR 10.1-10.3, 10.7\nAssignment 2\n\n\n15 Apr\nExplainable artificial intelligence (XAI)\nMolnar 8.1, 8.5, 9.2-9.6\n\n\n\n22 Apr\nSupport vector machines and nearest neighbours\nISLR 9.1-9.3\nAssignment 3\n\n\n29 Apr\nK-nearest neighbours and hierarchical clustering\nHOML Ch 20, 21\n\n\n\n06 May\nModel-based clustering and self-organising maps\nHOML Ch 22\n\n\n\n13 May\nEvaluating your clustering model\nCook and Laa Ch 12\nProject\n\n\n20 May\nProject presentations by Masters students"
  },
  {
    "objectID": "index.html#assessments",
    "href": "index.html#assessments",
    "title": "ETC3250/5250 Introduction to Machine Learning",
    "section": "Assessments",
    "text": "Assessments\n\nWeekly learning quizzes: 3%\nAssignment 1: 9%\nAssignment 2: 9%\nAssignment 3: 9%\nProject: 10%\nFinal exam: 60%"
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "ETC3250/5250 Introduction to Machine Learning",
    "section": "Software",
    "text": "Software\nHere is the code to install (most of) the R packages we will be using in this unit.\ninstall.packages(c(\"tidyverse\", \"tidymodels\", \"tourr\", \"geozoo\", \"mulgar\", \"ggpcp\", \"plotly\", \"detourr\", \"langevitour\", \"ggbeeswarm\", \"MASS\", \"GGally\", \"ISLR\", \"rpart\", \"rpart.plot\", \"randomForest\", \"e1071\", \"xgboost\", \"Rtsne\", \"classifly\", \"penalizedLDA\", \"nnet\", \"kernelshap\", \"shapviz\", \"iml\", \"DALEX\", \"cxhull\", \"fpc\", \"mclust\", \"ggdendro\", \"kohonen\", \"aweSOM\", \"patchwork\", \"ggthemes\", \"colorspace\", \"palmerpenguins\"), dependencies = TRUE)\nIf you run into problems completing the full install, the likely culprits are tidyverse and tidymodels. These are bundles of packages, and might fail at individual packages. To resolve the problems, install each package from the bundle individually, and don’t install any that fail on your system.\nIn addition, follow these instructions to set up tensorflow and keras, which requires having python installed.\nIf you are relatively new to R, working through the materials at https://learnr.numbat.space is an excellent way to up-skill. You are epsecially encouraged to work through Chapter 3, on Troubleshooting and asking for help, because at some point you will need help with your coding, and how you go about this matters and impacts the ability of others to help you.\nThe ISLR book also comes with python code, and you are welcome to do most of your work with python instead of R. However, what you submit for marking must be done with R."
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "ETC3250/5250 Resources",
    "section": "",
    "text": "Books\n\nAn Introduction to Statistical Learning (ISLR)\n\nThis book by James, Witten, Hastie and Tibshirani contains the primary content for the unit. It has the explanations for different methodology, practical labs, and a range of exercises to work through. Use the second edition, with Applications in R.\n\nHands-On Machine Learning with R\n\nThis book by Boehmke & Greenwell is an accessible and practical guide to many aspects of machine learning. It’s coverage of unsupervised classification is very good.\n\nTidy Modeling with R\n\nMachine learning is an active area of research across several disciplines, primarily statistics and computer science. Perhaps because of this there are many ways to define and fit models. The tidy modeling approach coordinates these into a consistent and understandable workflow. It doesn’t interface to all software, but getting started with machine learning using this mind-set helps you get organised despite the fragmented landscape. This book accompanies the software tidymodels.\n\nISLR tidymodels labs\n\nThis book contains the code to do most of the exercises from ISLR using the tidymodels thinking and coding style.\n\nInteractively exploring high-dimensional data and models in R\n\nThis book by Cook and Laa is the primary resource for learning how to visualise high-dimensions, how to explore the data, and to visually examine and diagnose models.\n\nInterpretable Machine Learning\n\nThis book by Christoph Molnar serves as a guide for making black box models explainable. It is an excellent resource for developing your understanding of the different types of models and how to diagnose and interpret them\n\n\nUseful links\n\nTensorFlow for R\nA gentle introduction to deep learning in R using Keras\n(M+C)² Blog"
  },
  {
    "objectID": "week11/index.html",
    "href": "week11/index.html",
    "title": "Week 11: Evaluating your clustering model",
    "section": "",
    "text": "Cook and Laa Ch 12"
  },
  {
    "objectID": "week11/index.html#main-reference",
    "href": "week11/index.html#main-reference",
    "title": "Week 11: Evaluating your clustering model",
    "section": "",
    "text": "Cook and Laa Ch 12"
  },
  {
    "objectID": "week11/index.html#what-you-will-learn-this-week",
    "href": "week11/index.html#what-you-will-learn-this-week",
    "title": "Week 11: Evaluating your clustering model",
    "section": "What you will learn this week",
    "text": "What you will learn this week\n\nConfusion tables\nCluster metrics"
  },
  {
    "objectID": "week11/index.html#assignments",
    "href": "week11/index.html#assignments",
    "title": "Week 11: Evaluating your clustering model",
    "section": "Assignments",
    "text": "Assignments\n\nProject is due on Friday 17 May."
  },
  {
    "objectID": "week2/index.html",
    "href": "week2/index.html",
    "title": "Week 2: Visualising your data and models",
    "section": "",
    "text": "Cook and Laa Ch 1, 3, 4, 5, 6, 13"
  },
  {
    "objectID": "week2/index.html#main-reference",
    "href": "week2/index.html#main-reference",
    "title": "Week 2: Visualising your data and models",
    "section": "",
    "text": "Cook and Laa Ch 1, 3, 4, 5, 6, 13"
  },
  {
    "objectID": "week2/index.html#what-you-will-learn-this-week",
    "href": "week2/index.html#what-you-will-learn-this-week",
    "title": "Week 2: Visualising your data and models",
    "section": "What you will learn this week",
    "text": "What you will learn this week\n\nDimension reduction methods: linear and non-linear\nVisualising high-dimensions using animations of linear projections\nScatterplot matrices\nParallel coordinate plots\nConcept of model-in-the-data-space, relative to data-in-the-moel-space"
  },
  {
    "objectID": "week2/index.html#assignments",
    "href": "week2/index.html#assignments",
    "title": "Week 2: Visualising your data and models",
    "section": "Assignments",
    "text": "Assignments\n\nAssignment 1 is due on Friday 22 March."
  },
  {
    "objectID": "week4/index.html",
    "href": "week4/index.html",
    "title": "Week 4: Logistic regression and discriminant analysis",
    "section": "",
    "text": "ISLR 4.3, 4.4"
  },
  {
    "objectID": "week4/index.html#main-reference",
    "href": "week4/index.html#main-reference",
    "title": "Week 4: Logistic regression and discriminant analysis",
    "section": "",
    "text": "ISLR 4.3, 4.4"
  },
  {
    "objectID": "week4/index.html#what-you-will-learn-this-week",
    "href": "week4/index.html#what-you-will-learn-this-week",
    "title": "Week 4: Logistic regression and discriminant analysis",
    "section": "What you will learn this week",
    "text": "What you will learn this week\n\nFitting a categorical response using logistic curves\nMultivariate summary statistics\nLinear discriminant analysis, assuming samples are elliptically shaped and equal in size\nQuadratic discriminant analysis, assuming samples are elliptically shaped and different in size\nDiscriminant space: making a low-dimensional visual summary"
  },
  {
    "objectID": "week4/index.html#assignments",
    "href": "week4/index.html#assignments",
    "title": "Week 4: Logistic regression and discriminant analysis",
    "section": "Assignments",
    "text": "Assignments\n\nAssignment 1 is due on Friday 22 March.\nAssignment 2 is due on Friday 12 April."
  },
  {
    "objectID": "week6/index.html",
    "href": "week6/index.html",
    "title": "Week 6: Neural networks and deep learning",
    "section": "",
    "text": "ISLR 10.1-10.3, 10.7"
  },
  {
    "objectID": "week6/index.html#main-reference",
    "href": "week6/index.html#main-reference",
    "title": "Week 6: Neural networks and deep learning",
    "section": "",
    "text": "ISLR 10.1-10.3, 10.7"
  },
  {
    "objectID": "week6/index.html#what-you-will-learn-this-week",
    "href": "week6/index.html#what-you-will-learn-this-week",
    "title": "Week 6: Neural networks and deep learning",
    "section": "What you will learn this week",
    "text": "What you will learn this week\n\nStructure of a neural network\nFitting neural networks\nDiagnosing the fit"
  },
  {
    "objectID": "week6/index.html#assignments",
    "href": "week6/index.html#assignments",
    "title": "Week 6: Neural networks and deep learning",
    "section": "Assignments",
    "text": "Assignments\n\nAssignment 2 is due on Friday 12 April.\nAssignment 3 is due on Friday 26 April."
  },
  {
    "objectID": "week8/index.html",
    "href": "week8/index.html",
    "title": "Week 8: Support vector machines and nearest neighbours",
    "section": "",
    "text": "ISLR 9.1-9.3"
  },
  {
    "objectID": "week8/index.html#main-reference",
    "href": "week8/index.html#main-reference",
    "title": "Week 8: Support vector machines and nearest neighbours",
    "section": "",
    "text": "ISLR 9.1-9.3"
  },
  {
    "objectID": "week8/index.html#what-you-will-learn-this-week",
    "href": "week8/index.html#what-you-will-learn-this-week",
    "title": "Week 8: Support vector machines and nearest neighbours",
    "section": "What you will learn this week",
    "text": "What you will learn this week\n\nSeparating hyperplanes\nNon-linear kernels\nNaive models using nearest neighbours"
  },
  {
    "objectID": "week8/index.html#assignments",
    "href": "week8/index.html#assignments",
    "title": "Week 8: Support vector machines and nearest neighbours",
    "section": "Assignments",
    "text": "Assignments\n\nAssignment 3 is due on Friday 26 April."
  }
]