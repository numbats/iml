---
title: "ETC3250/5250: Introduction to Machine Learning"
subtitle: "k-means clustering"
author: "Professor Di Cook"
email: "ETC3250.Clayton-x@monash.edu"
date: "Week 10a"
length: "50 minutes"
department: "Department of Econometrics and Business Statistics"
titlebgimg: "images/bg-02.png"
output:
  xaringan::moon_reader:
    css:
      - ninjutsu 
      - "assets/font-awesome-all.css"
      - "assets/tachyons-addon.css"
      - "assets/animate.css"
      - "assets/fira-code.css"
      - "assets/boxes.css"
      - "assets/table.css"
      - "assets/styles.css"
      - "assets/monash-brand.css"
      - "assets/monash-fonts.css"
      - "assets/slide-types.css"
      - "assets/custom.css"
      - "assets/panelset.css"
    self_contained: false 
    seal: false 
    chakra: 'lib/remark-latest.min.js'
    includes:
      in_header: "assets/head.html"
    lib_dir: lib
    #includes:
    #  in_header: "assets/custom.html"
    mathjax: "lib/mathjax-local/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
    nature:
      highlightStyle: magula
      highlightLanguage: r 
      highlightLines: true
      highlightSpans: false 
      countIncrementalSlides: false
      slideNumberFormat: '%current%/%total%'
      navigation:
        scroll: false 
        touch: true
        click: false
      ratio: '16:9'
---

```{r, include = FALSE}
current_file <- knitr::current_input()
basename <- gsub(".Rmd$", "", current_file)

knitr::opts_chunk$set(
  fig.path = sprintf("images/%s/", basename),
  fig.width = 6,
  fig.height = 4,
  out.width = "100%",
  fig.align = "center",
  fig.retina = 3,
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  cache = FALSE,
  cache.path = "cache/"
)
```

```{r titleslide, child="assets/titleslide.Rmd"}
```

---
## Cluster analysis

<br>

- The aim of cluster analysis is to group cases (objects) according to their similarity on the variables. It is also often called unsupervised classification, meaning that classification is the ultimate goal, but the classes (groups) are not known ahead of time. 
- Hence the first task in cluster analysis is to construct the class information. To determine closeness we start with measuring the interpoint distances.


---

## Cluster this!

```{r out.width="60%", fig.width=6}
library(tidyverse)
library(tourr)
library(gridExtra)
library(emo)
library(knitr)
library(kableExtra)

data(flea)
ggplot(data=flea) + geom_point(aes(x=tars1, y=aede1)) + theme(aspect.ratio=1) + xlab("") + ylab("")
# Add two more examples
```


---

## k-means clustering - algorithm

This is an iterative procedure. To use it the number of clusters, $k$, must be decided first.  The stages of the iteration are:

- Initialize by either (a) partitioning the data into k groups, and compute the $k$ group means or (b) an initial set of $k$ points as the first estimate of the cluster means (seed points).
- Loop over all observations reassigning them to the group with the closest mean.
- Recompute group means.
- Iterate steps 2 and 3 until convergence.

[Thean C. Lim's blog post](https://theanlim.rbind.io/post/clustering-k-means-k-means-and-gganimate/)

---
class: split-50
Some data `r emo::ji("cartwheel")`


.column[.pad50px[


```{r}
set.seed(8) #6
df <- tibble(lbl=letters[1:12], 
             x1=sample(1:10, 12, replace=TRUE),
             x2=sample(1:10, 12, replace=TRUE))
df[1:4,2] <- df[1:4,2] + 12
df[5:8,3] <- df[5:8,3] + 12
kable(df) %>%
  kable_styling("striped", position = "center", 
                row_label_position = "c", 
                font_size=24) %>%
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:3, border_right=TRUE, width="2cm") 
```
]]
.column[.pad50px[
```{r out.width="100%", fig.width=4, fig.height=4}
ggplot(data=df, aes(x1, x2)) + geom_text(aes(label=lbl)) + 
  xlab("") + ylab("") + theme_bw() + 
  xlim(c(1,22)) + ylim(c(1,22)) +
  theme(aspect.ratio=1) 
```
]]

---
class: split-50

.column[.pad10px[.content[

```{r}
# Initial means
xb <- data.frame(cl = factor(c(1, 2)), x1 = c(10,11), x2 = c(11, 9))
```

<br><br><br>

Select $k=2$, and set initial seed means <br>
$\bar{x}_1=$ (`r xb[1,-1]`) ,
$\bar{x}_2=$ (`r xb[2,-1]`) <br>
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot(data=df, aes(x1, x2)) + geom_text(aes(label=lbl)) + 
  xlab("") + ylab("") + theme_bw() + 
  xlim(c(1,22)) + ylim(c(1,22)) +
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  theme(aspect.ratio=1, legend.position="none") 
```

]]]

---
class: split-50

.column[.pad10px[.content[



<br><br><br>


Compute distances $(d_1, d_2)$ between each observation and each mean.

]]]
.column[.pad50px[.content[
```{r}
# Compute distances between each observation and each mean
d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km <- cbind(df, d1, d2)
df.km %>%
  kable("html", escape=F) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:5, border_right=TRUE, width="1cm") %>%
  column_spec(4:5, color="#7570B3") 
```
]]]

---
class: split-50 


.column[.pad10px[.content[

<br><br><br><br>
Assign the cluster membership


]]]
.column[.pad50px[.content[


```{r}
df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#7570B3")

```
]]]

---
class: split-50 
layout: false

.column[.pad10px[.content[

Assign the cluster membership

```{r}
df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#7570B3")

```
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  xlim(c(1,22)) + ylim(c(1,22)) +
  theme(aspect.ratio=1, legend.position="None") 
```
]]]

---
class: split-50 
layout: false

.column[.pad10px[.content[

Recompute means, and re-assign the cluster membership

```{r}
xb <- df.km %>%
  group_by(cl) %>%
  summarise(x1=mean(x1), x2=mean(x2))
xb1 <- data.frame(x1=xb$x1[1], x2=xb$x2[1])
xb2 <- data.frame(x1=xb$x1[2], x2=xb$x2[2])
```

$\bar{x}_1=$ (`r round(xb[1,-1], 0)`) ,
$\bar{x}_2=$ (`r round(xb[2,-1], 0)`) <br>

```{r}
d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#7570B3")

```
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  xlim(c(1,22)) + ylim(c(1,22)) +
  theme(aspect.ratio=1, legend.position="None") 
```
]]]

---
class: split-50 
layout: false

.column[.pad10px[.content[

Recompute means, and re-assign the cluster membership

```{r}
xb <- df.km %>%
  group_by(cl) %>%
  summarise(x1=mean(x1), x2=mean(x2))
xb1 <- data.frame(x1=xb$x1[1], x2=xb$x2[1])
xb2 <- data.frame(x1=xb$x1[2], x2=xb$x2[2])
```

$\bar{x}_1=$ (`r round(xb[1,-1], 0)`) ,
$\bar{x}_2=$ (`r round(xb[2,-1], 0)`) <br>

```{r}
d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#7570B3")

```
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  xlim(c(1,22)) + ylim(c(1,22)) +
  theme(aspect.ratio=1, legend.position="None") 
```
]]]

---
class: split-50 
layout: false

.column[.pad10px[.content[

Recompute means, and re-assign the cluster membership

```{r}
xb <- df.km %>%
  group_by(cl) %>%
  summarise(x1=mean(x1), x2=mean(x2))
xb1 <- data.frame(x1=xb$x1[1], x2=xb$x2[1])
xb2 <- data.frame(x1=xb$x1[2], x2=xb$x2[2])
```

$\bar{x}_1=$ (`r round(xb[1,-1], 0)`) ,
$\bar{x}_2=$ (`r round(xb[2,-1], 0)`) <br>

```{r}
d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#7570B3")

```
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  xlim(c(1,22)) + ylim(c(1,22)) +
  theme(aspect.ratio=1, legend.position="None") 
```
]]]

---
# Watch it animate

```{r out.width="50%", fig.width=4, fig.height=4}
xb <- data.frame(cl = factor(c(1, 2)), x1 = c(10,11), x2 = c(11, 9))

d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)

mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  xlim(c(1,22)) + ylim(c(1,22)) +
  theme(aspect.ratio=1, legend.position="None") 
```

---
count: false
# Watch it animate

```{r out.width="50%", fig.width=4, fig.height=4}
xb <- df.km %>%
  group_by(cl) %>%
  summarise(x1=mean(x1), x2=mean(x2))
xb1 <- data.frame(x1=xb$x1[1], x2=xb$x2[1])
xb2 <- data.frame(x1=xb$x1[2], x2=xb$x2[2])

d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)

mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  xlim(c(1,22)) + ylim(c(1,22)) +
  theme(aspect.ratio=1, legend.position="None") 
```

---
count: false
# Watch it animate

```{r out.width="50%", fig.width=4, fig.height=4}
xb <- df.km %>%
  group_by(cl) %>%
  summarise(x1=mean(x1), x2=mean(x2))
xb1 <- data.frame(x1=xb$x1[1], x2=xb$x2[1])
xb2 <- data.frame(x1=xb$x1[2], x2=xb$x2[2])

d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)

mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  xlim(c(1,22)) + ylim(c(1,22)) +
  theme(aspect.ratio=1, legend.position="None") 
```

---

## Example

```{r out.width="50%", fig.width=4, fig.height=4}
ggplot(data=flea) + geom_point(aes(x=tars1, y=aede1)) + theme(aspect.ratio=1) + xlab("") + ylab("")
```




---
class: split-50 
layout: false


.column[.pad50px[.content[

$k=2$

```{r  out.width="100%", fig.width=4, fig.height=4}
set.seed(31)
flea$km2 <- kmeans(scale(flea[,c(1,4)]), 2, nstart=5)$cluster
flea$km3 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=5)$cluster
flea$km4 <- kmeans(scale(flea[,c(1,4)]), 4, nstart=5)$cluster
flea$km5 <- kmeans(scale(flea[,c(1,4)]), 5, nstart=5)$cluster
ggplot(data=flea) + 
  geom_point(aes(x=tars1, y=aede1, colour=factor(km2),
                 shape=factor(km2))) +
  scale_colour_brewer("", palette="Dark2") + 
  theme(aspect.ratio=1, legend.position = "none") + 
  xlab("") + ylab("")
```
]]]
.column[.pad50px[.content[

$k=3$

```{r out.width="100%", fig.width=4, fig.height=4}
ggplot(data=flea) + 
  geom_point(aes(x=tars1, y=aede1, colour=factor(km3),
                 shape=factor(km3))) +
  scale_colour_brewer("", palette="Dark2") + 
  theme(aspect.ratio=1, legend.position = "none") + 
  xlab("") + ylab("")
```
]]]

---
class: split-50 
layout: false


.column[.pad50px[.content[

$k=4$

```{r  out.width="100%", fig.width=4, fig.height=4}
ggplot(data=flea) + 
  geom_point(aes(x=tars1, y=aede1, colour=factor(km4),
                 shape=factor(km4))) +
  scale_colour_brewer("", palette="Dark2") + 
  theme(aspect.ratio=1, legend.position = "none") + 
  xlab("") + ylab("")
```
]]]
.column[.pad50px[.content[

$k=5$

```{r out.width="100%", fig.width=4, fig.height=4}
ggplot(data=flea) + 
  geom_point(aes(x=tars1, y=aede1, colour=factor(km5),
                 shape=factor(km5))) +
  scale_colour_brewer("", palette="Dark2") + 
  theme(aspect.ratio=1, legend.position = "none") + 
  xlab("") + ylab("")
```
]]]

---
## Choosing k

.monash-blue2[Cluster statistics]

- .monash-orange2[WBRatio]: average within/average between want it to be low, but always drops for each additional cluster so look for large drops
- .monash-orange2[Hubert Gamma]: (s+ - s-)/(s+ + s-) where $s+=$sum of number of within $<$ between, $s-=$ sum of number within $>$ between, want this to be high
- .monash-orange2[Dunn]: smallest distance between points from different clusters/maximum distance of points within any cluster, want this to be high
- .monash-orange2[Calinski-Harabasz Index]: $\frac{\sum_{i=1}^p B_{ii}/(k-1)}{\sum_{i=1}^p W_{ii}/(n-k)}$ want this to be high


---

## Choosing k

```{r out.width="60%", fig.width=8, fig.height=6}
library(fpc)
set.seed(31)
f.km <- NULL; f.km.stats <- NULL
for (i in 2:10) {
  cl <- kmeans(scale(flea[,c(1,4)]), i, nstart=5)$cluster
  x <- cluster.stats(dist(scale(flea[,c(1,4)])), cl)
  f.km <- cbind(f.km, cl)
  f.km.stats <- rbind(f.km.stats, c(x$within.cluster.ss, x$wb.ratio, x$ch,
                                    x$pearsongamma, x$dunn, x$dunn2))
}
colnames(f.km.stats) <- c("within.cluster.ss","wb.ratio", "ch", "pearsongamma", "dunn", "dunn2")
f.km.stats <- data.frame(f.km.stats)
f.km.stats$cl <- 2:10
f.km.stats.m <- f.km.stats %>% 
  gather(stat, value, -cl)
ggplot(data=f.km.stats.m) + 
  geom_line(aes(x=cl, y=value)) + xlab("# clusters") + ylab("") +
  facet_wrap(~stat, ncol=3, scales = "free_y") + 
  theme_bw()
```


---
## k-means caveats

.monash-blue2[Effect of seed]

- The k-means algorithm can yield quite different results depending on the initial seed.
- Example runs used 5 random starts, and used the `within.cluster.ss` metric to decide on the best solution.

```{r out.width="100%", fig.width=9, fig.height=3}
set.seed(20190513)
flea$cl1 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
flea$cl2 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
flea$cl3 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
flea$cl4 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
flea$cl5 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
flea$cl6 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
p1 <- ggplot(data=flea, aes(x=tars1, y=aede1, 
                            colour=factor(cl1))) + 
  geom_point() +
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() + 
  theme(aspect.ratio=1, legend.position="none") 
p2 <- ggplot(data=flea, aes(x=tars1, y=aede1, 
                            colour=factor(cl2))) + 
  geom_point() +
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() + 
  theme(aspect.ratio=1, legend.position="none") 
p3 <- ggplot(data=flea, aes(x=tars1, y=aede1, 
                            colour=factor(cl5))) + 
  geom_point() +
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() + 
  theme(aspect.ratio=1, legend.position="none") 
grid.arrange(p1, p2, p3, ncol=3)
```



---
## Interpoint distance measures 

.monash-blue2[Euclidean]

- Cluster analysis depends on the interpoint distances, points close together should be grouped together
- Euclidean distance was used for the example. Let $A=(x_{a1}, x_{a2}, ..., x_{ap}), B=(x_{b1}, x_{b2}, ..., x_{bp})$

\begin{align*}
d_{EUC}(A, B) &= \sqrt{\sum_{j=1}^p (x_{aj}-x_{bj})^2} &\\
&= \sqrt{((X_A-X_B)^T (X_A-X_B))}&
\end{align*}



---
class: split-50
layout: false

.column[.pad10px[

### Other distance metrics

- Mahalanobis (or statistical) distance

$$\sqrt{((X_A-X_B)^TS^{-1} (X_A-X_B))}$$

- Manhattan: 

$$\sum_{j=1}^p|(X_{aj}-X_{bj})|$$

- Minkowski: 

$$(\sum_{j=1}^p|(X_{aj}-X_{bj})|^m)^{1/m}$$
]]
.column[.pad10px[

### Distances for count data

- Canberra: 

$$\frac{1}{n_z}\sum_{j=1}^p\frac{X_{aj}-X_{bj}}{X_{aj}+X_{bj}}$$

- Bray-Curtis: 

$$\frac{\sum_{j=1}^p|X_{aj}-X_{bj}|}{\sum_{j=1}^p(X_{aj}+X_{bj})}$$

]]
---
## Interpoint distance measures - Euclidean

.monash-blue2[Rules for any metric to be a distance]

1. $d(A, B) \geq 0$
2. $d(A, A) = 0$
3. $d(A, B) = d(B, A)$
4. Metric dissimilarity satisfies 
$d(A, B) \leq d(A, C) + d(C, B)$, and an ultrametric dissimilarity satisfies
$d(A, B) \leq max\{d(A, C), d(C, B)\}$


---

```{r endslide, child="assets/endslide.Rmd"}
```
